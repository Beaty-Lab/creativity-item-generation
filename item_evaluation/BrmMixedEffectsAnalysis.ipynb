{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Linear mixed effects modeling for CPIG items\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IGM</th>\n",
       "      <th>IRGM</th>\n",
       "      <th>SSM</th>\n",
       "      <th>RPT</th>\n",
       "      <th>Round</th>\n",
       "      <th>Originality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>CS</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Mean Originality - Round 1</td>\n",
       "      <td>1.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>CS</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Mean Originality - Round 1</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>CS</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Mean Originality - Round 1</td>\n",
       "      <td>1.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>CS</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Mean Originality - Round 1</td>\n",
       "      <td>1.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>CS</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Mean Originality - Round 1</td>\n",
       "      <td>1.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>CS</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Mean Originality - Round 5</td>\n",
       "      <td>1.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>CS</td>\n",
       "      <td>Psychometric</td>\n",
       "      <td>Mean Originality - Round 5</td>\n",
       "      <td>1.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>CS</td>\n",
       "      <td>Psychometric</td>\n",
       "      <td>Mean Originality - Round 5</td>\n",
       "      <td>1.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>CS</td>\n",
       "      <td>Psychometric</td>\n",
       "      <td>Mean Originality - Round 5</td>\n",
       "      <td>1.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>CS</td>\n",
       "      <td>Demographic</td>\n",
       "      <td>Mean Originality - Round 5</td>\n",
       "      <td>1.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   IGM                              IRGM SSM  \\\n",
       "0    meta-llama/Llama-3.1-70B-Instruct  meta-llama/Llama-3.1-8B-Instruct  CS   \n",
       "1    meta-llama/Llama-3.1-70B-Instruct  meta-llama/Llama-3.1-8B-Instruct  CS   \n",
       "2    meta-llama/Llama-3.1-70B-Instruct  meta-llama/Llama-3.1-8B-Instruct  CS   \n",
       "3    meta-llama/Llama-3.1-70B-Instruct  meta-llama/Llama-3.1-8B-Instruct  CS   \n",
       "4    meta-llama/Llama-3.1-70B-Instruct  meta-llama/Llama-3.1-8B-Instruct  CS   \n",
       "..                                 ...                               ...  ..   \n",
       "171              lmsys/vicuna-13b-v1.5     meta-llama/Llama-2-7b-chat-hf  CS   \n",
       "172              lmsys/vicuna-13b-v1.5     meta-llama/Llama-2-7b-chat-hf  CS   \n",
       "173              lmsys/vicuna-13b-v1.5     meta-llama/Llama-2-7b-chat-hf  CS   \n",
       "174              lmsys/vicuna-13b-v1.5     meta-llama/Llama-2-7b-chat-hf  CS   \n",
       "175              lmsys/vicuna-13b-v1.5     meta-llama/Llama-2-7b-chat-hf  CS   \n",
       "\n",
       "              RPT                       Round  Originality  \n",
       "0        Baseline  Mean Originality - Round 1        1.419  \n",
       "1        Baseline  Mean Originality - Round 1        1.414  \n",
       "2        Baseline  Mean Originality - Round 1        1.355  \n",
       "3     Demographic  Mean Originality - Round 1        1.305  \n",
       "4     Demographic  Mean Originality - Round 1        1.398  \n",
       "..            ...                         ...          ...  \n",
       "171      Baseline  Mean Originality - Round 5        1.336  \n",
       "172  Psychometric  Mean Originality - Round 5        1.454  \n",
       "173  Psychometric  Mean Originality - Round 5        1.454  \n",
       "174  Psychometric  Mean Originality - Round 5        1.454  \n",
       "175   Demographic  Mean Originality - Round 5        1.353  \n",
       "\n",
       "[176 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/aml7990/Code/creativity-item-generation/item_evaluation/linear_regression/Summary_CPS_trials.csv\")\n",
    "# df = df[[\"Item Gen Model\", \"Item Response Gen Model\", \"Shot Selection Method\", \"Response Prompt Type\", \"Mean Originality - Round 5\"]]\n",
    "df.dropna(inplace=True)\n",
    "df = pd.melt(df, id_vars=[\"Item Gen Model\", \"Item Response Gen Model\", \"Shot Selection Method\", \"Response Prompt Type\"], var_name=\"Round\", value_name=\"Mean Originality\")\n",
    "df.rename(columns={\n",
    "    \"Item Gen Model\": \"IGM\",\n",
    "    \"Item Response Gen Model\": \"IRGM\",\n",
    "    \"Shot Selection Method\": \"SSM\",\n",
    "    \"Response Prompt Type\": \"RPT\",\n",
    "    \"Mean Originality\": \"Originality\"\n",
    "}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IGM\n",
       "gpt-4o-mini                              72\n",
       "claude-3-haiku                           30\n",
       "meta-llama/Llama-3.1-70B-Instruct        18\n",
       "mistralai/Mistral-Large-Instruct-2407    18\n",
       "lmsys/vicuna-13b-v1.5                    16\n",
       "meta-llama/Llama-2-13b-chat-hf           14\n",
       "meta-llama/Llama-2-70b-chat-hf            6\n",
       "lmsys/vicuna-7b-v1.5                      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IGM\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRGM\n",
       "meta-llama/Llama-3.1-8B-Instruct    90\n",
       "meta-llama/Llama-2-7b-chat-hf       50\n",
       "meta-llama/Llama-3.2-3B-Instruct    18\n",
       "lmsys/vicuna-7b-v1.5                18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IRGM\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Originality</td>   <th>  R-squared:         </th> <td>   0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>1.34e-47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:47:06</td>     <th>  Log-Likelihood:    </th> <td>  89.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   176</td>      <th>  AIC:               </th> <td>  -146.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   160</td>      <th>  BIC:               </th> <td>  -95.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                         <td></td>                            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                       <td>    0.6448</td> <td>    0.099</td> <td>    6.533</td> <td> 0.000</td> <td>    0.450</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]</th>                           <td>    0.2499</td> <td>    0.089</td> <td>    2.794</td> <td> 0.006</td> <td>    0.073</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]</th>                 <td>   -0.0147</td> <td>    0.071</td> <td>   -0.208</td> <td> 0.836</td> <td>   -0.155</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]</th>                  <td>    0.1853</td> <td>    0.136</td> <td>    1.363</td> <td> 0.175</td> <td>   -0.083</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]</th>        <td>   -0.1051</td> <td>    0.072</td> <td>   -1.457</td> <td> 0.147</td> <td>   -0.248</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]</th>        <td>    0.3748</td> <td>    0.083</td> <td>    4.516</td> <td> 0.000</td> <td>    0.211</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]</th>     <td>    0.1003</td> <td>    0.051</td> <td>    1.967</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]</th> <td>    0.1268</td> <td>    0.051</td> <td>    2.486</td> <td> 0.014</td> <td>    0.026</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]</th>        <td>    0.2091</td> <td>    0.135</td> <td>    1.546</td> <td> 0.124</td> <td>   -0.058</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]</th>     <td>    0.5909</td> <td>    0.089</td> <td>    6.606</td> <td> 0.000</td> <td>    0.414</td> <td>    0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]</th>     <td>    0.3149</td> <td>    0.051</td> <td>    6.175</td> <td> 0.000</td> <td>    0.214</td> <td>    0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Greedy]</th>                                <td>   -0.1142</td> <td>    0.089</td> <td>   -1.277</td> <td> 0.203</td> <td>   -0.291</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Random]</th>                                <td>   -0.2042</td> <td>    0.073</td> <td>   -2.779</td> <td> 0.006</td> <td>   -0.349</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Demographic]</th>                           <td>   -0.0123</td> <td>    0.031</td> <td>   -0.405</td> <td> 0.686</td> <td>   -0.073</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Psychometric]</th>                          <td>    0.1929</td> <td>    0.030</td> <td>    6.391</td> <td> 0.000</td> <td>    0.133</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Round)[T.Mean Originality - Round 5]</th>          <td>    0.3247</td> <td>    0.023</td> <td>   14.079</td> <td> 0.000</td> <td>    0.279</td> <td>    0.370</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.456</td> <th>  Durbin-Watson:     </th> <td>   1.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.009</td> <th>  Jarque-Bera (JB):  </th> <td>  18.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.144</td> <th>  Prob(JB):          </th> <td>9.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.563</td> <th>  Cond. No.          </th> <td>    30.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                  &   Originality    & \\textbf{  R-squared:         } &     0.797   \\\\\n",
       "\\textbf{Model:}                                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.778   \\\\\n",
       "\\textbf{Method:}                                         &  Least Squares   & \\textbf{  F-statistic:       } &     41.98   \\\\\n",
       "\\textbf{Date:}                                           & Wed, 18 Dec 2024 & \\textbf{  Prob (F-statistic):} &  1.34e-47   \\\\\n",
       "\\textbf{Time:}                                           &     11:47:06     & \\textbf{  Log-Likelihood:    } &    89.096   \\\\\n",
       "\\textbf{No. Observations:}                               &         176      & \\textbf{  AIC:               } &    -146.2   \\\\\n",
       "\\textbf{Df Residuals:}                                   &         160      & \\textbf{  BIC:               } &    -95.46   \\\\\n",
       "\\textbf{Df Model:}                                       &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                       &       0.6448  &        0.099     &     6.533  &         0.000        &        0.450    &        0.840     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]}                           &       0.2499  &        0.089     &     2.794  &         0.006        &        0.073    &        0.426     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]}                 &      -0.0147  &        0.071     &    -0.208  &         0.836        &       -0.155    &        0.125     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]}                  &       0.1853  &        0.136     &     1.363  &         0.175        &       -0.083    &        0.454     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]}        &      -0.1051  &        0.072     &    -1.457  &         0.147        &       -0.248    &        0.037     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]}        &       0.3748  &        0.083     &     4.516  &         0.000        &        0.211    &        0.539     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]}     &       0.1003  &        0.051     &     1.967  &         0.051        &       -0.000    &        0.201     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]} &       0.1268  &        0.051     &     2.486  &         0.014        &        0.026    &        0.227     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]}        &       0.2091  &        0.135     &     1.546  &         0.124        &       -0.058    &        0.476     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]}     &       0.5909  &        0.089     &     6.606  &         0.000        &        0.414    &        0.767     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]}     &       0.3149  &        0.051     &     6.175  &         0.000        &        0.214    &        0.416     \\\\\n",
       "\\textbf{C(SSM)[T.Greedy]}                                &      -0.1142  &        0.089     &    -1.277  &         0.203        &       -0.291    &        0.062     \\\\\n",
       "\\textbf{C(SSM)[T.Random]}                                &      -0.2042  &        0.073     &    -2.779  &         0.006        &       -0.349    &       -0.059     \\\\\n",
       "\\textbf{C(RPT)[T.Demographic]}                           &      -0.0123  &        0.031     &    -0.405  &         0.686        &       -0.073    &        0.048     \\\\\n",
       "\\textbf{C(RPT)[T.Psychometric]}                          &       0.1929  &        0.030     &     6.391  &         0.000        &        0.133    &        0.252     \\\\\n",
       "\\textbf{C(Round)[T.Mean Originality - Round 5]}          &       0.3247  &        0.023     &    14.079  &         0.000        &        0.279    &        0.370     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  9.456 & \\textbf{  Durbin-Watson:     } &    1.358  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.009 & \\textbf{  Jarque-Bera (JB):  } &   18.516  \\\\\n",
       "\\textbf{Skew:}          & -0.144 & \\textbf{  Prob(JB):          } & 9.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.563 & \\textbf{  Cond. No.          } &     30.2  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Originality   R-squared:                       0.797\n",
       "Model:                            OLS   Adj. R-squared:                  0.778\n",
       "Method:                 Least Squares   F-statistic:                     41.98\n",
       "Date:                Wed, 18 Dec 2024   Prob (F-statistic):           1.34e-47\n",
       "Time:                        11:47:06   Log-Likelihood:                 89.096\n",
       "No. Observations:                 176   AIC:                            -146.2\n",
       "Df Residuals:                     160   BIC:                            -95.46\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================================\n",
       "                                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                           0.6448      0.099      6.533      0.000       0.450       0.840\n",
       "C(IGM)[T.gpt-4o-mini]                               0.2499      0.089      2.794      0.006       0.073       0.426\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]                    -0.0147      0.071     -0.208      0.836      -0.155       0.125\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]                      0.1853      0.136      1.363      0.175      -0.083       0.454\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]           -0.1051      0.072     -1.457      0.147      -0.248       0.037\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]            0.3748      0.083      4.516      0.000       0.211       0.539\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]         0.1003      0.051      1.967      0.051      -0.000       0.201\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]     0.1268      0.051      2.486      0.014       0.026       0.227\n",
       "C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]            0.2091      0.135      1.546      0.124      -0.058       0.476\n",
       "C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]         0.5909      0.089      6.606      0.000       0.414       0.767\n",
       "C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]         0.3149      0.051      6.175      0.000       0.214       0.416\n",
       "C(SSM)[T.Greedy]                                   -0.1142      0.089     -1.277      0.203      -0.291       0.062\n",
       "C(SSM)[T.Random]                                   -0.2042      0.073     -2.779      0.006      -0.349      -0.059\n",
       "C(RPT)[T.Demographic]                              -0.0123      0.031     -0.405      0.686      -0.073       0.048\n",
       "C(RPT)[T.Psychometric]                              0.1929      0.030      6.391      0.000       0.133       0.252\n",
       "C(Round)[T.Mean Originality - Round 5]              0.3247      0.023     14.079      0.000       0.279       0.370\n",
       "==============================================================================\n",
       "Omnibus:                        9.456   Durbin-Watson:                   1.358\n",
       "Prob(Omnibus):                  0.009   Jarque-Bera (JB):               18.516\n",
       "Skew:                          -0.144   Prob(JB):                     9.54e-05\n",
       "Kurtosis:                       4.563   Cond. No.                         30.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The simpliest possible model: simply treat all variables as independent\n",
    "model1 = smf.ols(formula=\"Originality ~ C(IGM) + C(IRGM) + C(SSM) + C(RPT) + C(Round)\", data=df)\n",
    "res = model1.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Originality</td>   <th>  R-squared:         </th> <td>   0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>1.34e-47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:55:16</td>     <th>  Log-Likelihood:    </th> <td>  89.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   176</td>      <th>  AIC:               </th> <td>  -146.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   160</td>      <th>  BIC:               </th> <td>  -95.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                              <td></td>                                                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                                 <td>    0.7976</td> <td>    0.025</td> <td>   31.453</td> <td> 0.000</td> <td>    0.748</td> <td>    0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Greedy]</th>                                                                          <td>   -0.1142</td> <td>    0.089</td> <td>   -1.277</td> <td> 0.203</td> <td>   -0.291</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Random]</th>                                                                          <td>   -0.2042</td> <td>    0.073</td> <td>   -2.779</td> <td> 0.006</td> <td>   -0.349</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Demographic]</th>                                                                     <td>   -0.0123</td> <td>    0.031</td> <td>   -0.405</td> <td> 0.686</td> <td>   -0.073</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Psychometric]</th>                                                                    <td>    0.1929</td> <td>    0.030</td> <td>    6.391</td> <td> 0.000</td> <td>    0.133</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Round)[T.Mean Originality - Round 5]</th>                                                    <td>    0.3247</td> <td>    0.023</td> <td>   14.079</td> <td> 0.000</td> <td>    0.279</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]</th>                                                  <td>    0.0564</td> <td>    0.049</td> <td>    1.152</td> <td> 0.251</td> <td>   -0.040</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]</th>                                               <td>    0.4381</td> <td>    0.032</td> <td>   13.513</td> <td> 0.000</td> <td>    0.374</td> <td>    0.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]</th>                                               <td>    0.2060</td> <td>    0.018</td> <td>   11.255</td> <td> 0.000</td> <td>    0.170</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                                       <td>    0.0971</td> <td>    0.032</td> <td>    2.995</td> <td> 0.003</td> <td>    0.033</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                             <td> 5.807e-17</td> <td> 5.91e-17</td> <td>    0.983</td> <td> 0.327</td> <td>-5.86e-17</td> <td> 1.75e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                              <td> 3.553e-17</td> <td> 1.82e-17</td> <td>    1.948</td> <td> 0.053</td> <td>-4.91e-19</td> <td> 7.16e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                    <td>-6.972e-17</td> <td> 1.35e-17</td> <td>   -5.163</td> <td> 0.000</td> <td>-9.64e-17</td> <td>-4.31e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                    <td>  2.81e-16</td> <td> 1.08e-16</td> <td>    2.590</td> <td> 0.010</td> <td> 6.67e-17</td> <td> 4.95e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>                 <td>-9.295e-17</td> <td> 3.04e-17</td> <td>   -3.054</td> <td> 0.003</td> <td>-1.53e-16</td> <td>-3.28e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[lmsys/vicuna-7b-v1.5]</th>             <td>-1.773e-18</td> <td> 3.41e-18</td> <td>   -0.520</td> <td> 0.604</td> <td>-8.51e-18</td> <td> 4.96e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>                              <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>                    <td>   -0.0147</td> <td>    0.071</td> <td>   -0.208</td> <td> 0.836</td> <td>   -0.155</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>                     <td>    0.1853</td> <td>    0.136</td> <td>    1.363</td> <td> 0.175</td> <td>   -0.083</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>           <td>   -0.1051</td> <td>    0.072</td> <td>   -1.457</td> <td> 0.147</td> <td>   -0.248</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>           <td>    0.3748</td> <td>    0.083</td> <td>    4.516</td> <td> 0.000</td> <td>    0.211</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]</th>    <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>                           <td>    0.2499</td> <td>    0.089</td> <td>    2.794</td> <td> 0.006</td> <td>    0.073</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>                 <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>                  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th>     <td>    0.1003</td> <td>    0.051</td> <td>    1.967</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]</th> <td>    0.1268</td> <td>    0.051</td> <td>    2.486</td> <td> 0.014</td> <td>    0.026</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>                           <td>    0.2060</td> <td>    0.018</td> <td>   11.255</td> <td> 0.000</td> <td>    0.170</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>                 <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>                  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th>     <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.456</td> <th>  Durbin-Watson:     </th> <td>   1.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.009</td> <th>  Jarque-Bera (JB):  </th> <td>  18.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.144</td> <th>  Prob(JB):          </th> <td>9.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.563</td> <th>  Cond. No.          </th> <td>2.42e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.22e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                                            &   Originality    & \\textbf{  R-squared:         } &     0.797   \\\\\n",
       "\\textbf{Model:}                                                                                    &       OLS        & \\textbf{  Adj. R-squared:    } &     0.778   \\\\\n",
       "\\textbf{Method:}                                                                                   &  Least Squares   & \\textbf{  F-statistic:       } &     41.98   \\\\\n",
       "\\textbf{Date:}                                                                                     & Wed, 18 Dec 2024 & \\textbf{  Prob (F-statistic):} &  1.34e-47   \\\\\n",
       "\\textbf{Time:}                                                                                     &     11:55:16     & \\textbf{  Log-Likelihood:    } &    89.096   \\\\\n",
       "\\textbf{No. Observations:}                                                                         &         176      & \\textbf{  AIC:               } &    -146.2   \\\\\n",
       "\\textbf{Df Residuals:}                                                                             &         160      & \\textbf{  BIC:               } &    -95.46   \\\\\n",
       "\\textbf{Df Model:}                                                                                 &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                                          &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                                                 &       0.7976  &        0.025     &    31.453  &         0.000        &        0.748    &        0.848     \\\\\n",
       "\\textbf{C(SSM)[T.Greedy]}                                                                          &      -0.1142  &        0.089     &    -1.277  &         0.203        &       -0.291    &        0.062     \\\\\n",
       "\\textbf{C(SSM)[T.Random]}                                                                          &      -0.2042  &        0.073     &    -2.779  &         0.006        &       -0.349    &       -0.059     \\\\\n",
       "\\textbf{C(RPT)[T.Demographic]}                                                                     &      -0.0123  &        0.031     &    -0.405  &         0.686        &       -0.073    &        0.048     \\\\\n",
       "\\textbf{C(RPT)[T.Psychometric]}                                                                    &       0.1929  &        0.030     &     6.391  &         0.000        &        0.133    &        0.252     \\\\\n",
       "\\textbf{C(Round)[T.Mean Originality - Round 5]}                                                    &       0.3247  &        0.023     &    14.079  &         0.000        &        0.279    &        0.370     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]}                                                  &       0.0564  &        0.049     &     1.152  &         0.251        &       -0.040    &        0.153     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]}                                               &       0.4381  &        0.032     &    13.513  &         0.000        &        0.374    &        0.502     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]}                                               &       0.2060  &        0.018     &    11.255  &         0.000        &        0.170    &        0.242     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                                       &       0.0971  &        0.032     &     2.995  &         0.003        &        0.033    &        0.161     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                             &    5.807e-17  &     5.91e-17     &     0.983  &         0.327        &    -5.86e-17    &     1.75e-16     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                              &    3.553e-17  &     1.82e-17     &     1.948  &         0.053        &    -4.91e-19    &     7.16e-17     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                    &   -6.972e-17  &     1.35e-17     &    -5.163  &         0.000        &    -9.64e-17    &    -4.31e-17     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                    &     2.81e-16  &     1.08e-16     &     2.590  &         0.010        &     6.67e-17    &     4.95e-16     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[lmsys/vicuna-7b-v1.5]}                 &   -9.295e-17  &     3.04e-17     &    -3.054  &         0.003        &    -1.53e-16    &    -3.28e-17     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[lmsys/vicuna-7b-v1.5]}             &   -1.773e-18  &     3.41e-18     &    -0.520  &         0.604        &    -8.51e-18    &     4.96e-18     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}                              &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}                    &      -0.0147  &        0.071     &    -0.208  &         0.836        &       -0.155    &        0.125     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}                     &       0.1853  &        0.136     &     1.363  &         0.175        &       -0.083    &        0.454     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}           &      -0.1051  &        0.072     &    -1.457  &         0.147        &       -0.248    &        0.037     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}           &       0.3748  &        0.083     &     4.516  &         0.000        &        0.211    &        0.539     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]}    &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}                           &       0.2499  &        0.089     &     2.794  &         0.006        &        0.073    &        0.426     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}                 &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}                  &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]}     &       0.1003  &        0.051     &     1.967  &         0.051        &       -0.000    &        0.201     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]} &       0.1268  &        0.051     &     2.486  &         0.014        &        0.026    &        0.227     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}                           &       0.2060  &        0.018     &    11.255  &         0.000        &        0.170    &        0.242     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}                 &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}                  &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]}     &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]} &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  9.456 & \\textbf{  Durbin-Watson:     } &    1.358  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.009 & \\textbf{  Jarque-Bera (JB):  } &   18.516  \\\\\n",
       "\\textbf{Skew:}          & -0.144 & \\textbf{  Prob(JB):          } & 9.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.563 & \\textbf{  Cond. No.          } & 2.42e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 6.22e-31. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Originality   R-squared:                       0.797\n",
       "Model:                            OLS   Adj. R-squared:                  0.778\n",
       "Method:                 Least Squares   F-statistic:                     41.98\n",
       "Date:                Wed, 18 Dec 2024   Prob (F-statistic):           1.34e-47\n",
       "Time:                        11:55:16   Log-Likelihood:                 89.096\n",
       "No. Observations:                 176   AIC:                            -146.2\n",
       "Df Residuals:                     160   BIC:                            -95.46\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================================================================================\n",
       "                                                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                                     0.7976      0.025     31.453      0.000       0.748       0.848\n",
       "C(SSM)[T.Greedy]                                                                             -0.1142      0.089     -1.277      0.203      -0.291       0.062\n",
       "C(SSM)[T.Random]                                                                             -0.2042      0.073     -2.779      0.006      -0.349      -0.059\n",
       "C(RPT)[T.Demographic]                                                                        -0.0123      0.031     -0.405      0.686      -0.073       0.048\n",
       "C(RPT)[T.Psychometric]                                                                        0.1929      0.030      6.391      0.000       0.133       0.252\n",
       "C(Round)[T.Mean Originality - Round 5]                                                        0.3247      0.023     14.079      0.000       0.279       0.370\n",
       "C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]                                                      0.0564      0.049      1.152      0.251      -0.040       0.153\n",
       "C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]                                                   0.4381      0.032     13.513      0.000       0.374       0.502\n",
       "C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]                                                   0.2060      0.018     11.255      0.000       0.170       0.242\n",
       "C(IGM)[T.gpt-4o-mini]:C(IRGM)[lmsys/vicuna-7b-v1.5]                                           0.0971      0.032      2.995      0.003       0.033       0.161\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]                              5.807e-17   5.91e-17      0.983      0.327   -5.86e-17    1.75e-16\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[lmsys/vicuna-7b-v1.5]                               3.553e-17   1.82e-17      1.948      0.053   -4.91e-19    7.16e-17\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]                    -6.972e-17   1.35e-17     -5.163      0.000   -9.64e-17   -4.31e-17\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[lmsys/vicuna-7b-v1.5]                      2.81e-16   1.08e-16      2.590      0.010    6.67e-17    4.95e-16\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[lmsys/vicuna-7b-v1.5]                 -9.295e-17   3.04e-17     -3.054      0.003   -1.53e-16   -3.28e-17\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[lmsys/vicuna-7b-v1.5]             -1.773e-18   3.41e-18     -0.520      0.604   -8.51e-18    4.96e-18\n",
       "C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]                                       0          0        nan        nan           0           0\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]                       -0.0147      0.071     -0.208      0.836      -0.155       0.125\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]                         0.1853      0.136      1.363      0.175      -0.083       0.454\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]              -0.1051      0.072     -1.457      0.147      -0.248       0.037\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]               0.3748      0.083      4.516      0.000       0.211       0.539\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-2-7b-chat-hf]             0          0        nan        nan           0           0\n",
       "C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]                               0.2499      0.089      2.794      0.006       0.073       0.426\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]                          0          0        nan        nan           0           0\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]                           0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]         0.1003      0.051      1.967      0.051      -0.000       0.201\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.1-8B-Instruct]     0.1268      0.051      2.486      0.014       0.026       0.227\n",
       "C(IGM)[T.gpt-4o-mini]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]                               0.2060      0.018     11.255      0.000       0.170       0.242\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]                          0          0        nan        nan           0           0\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]                           0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]              0          0        nan        nan           0           0\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(IRGM)[meta-llama/Llama-3.2-3B-Instruct]          0          0        nan        nan           0           0\n",
       "==============================================================================\n",
       "Omnibus:                        9.456   Durbin-Watson:                   1.358\n",
       "Prob(Omnibus):                  0.009   Jarque-Bera (JB):               18.516\n",
       "Skew:                          -0.144   Prob(JB):                     9.54e-05\n",
       "Kurtosis:                       4.563   Cond. No.                     2.42e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.22e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add interactions between generator and responder\n",
    "# the nas worry me in these models, I think its better to fit separate models that don't have them\n",
    "model2 = smf.ols(formula=\"Originality ~ C(IGM) : C(IRGM) + C(SSM) + C(RPT) + C(Round)\", data=df)\n",
    "res = model2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Originality</td>   <th>  R-squared:         </th> <td>   0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>3.67e-47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:55:44</td>     <th>  Log-Likelihood:    </th> <td>  90.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   176</td>      <th>  AIC:               </th> <td>  -146.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   159</td>      <th>  BIC:               </th> <td>  -92.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                 <td></td>                                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                      <td>    0.7543</td> <td>    0.027</td> <td>   27.961</td> <td> 0.000</td> <td>    0.701</td> <td>    0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]</th>                       <td>    0.1325</td> <td>    0.051</td> <td>    2.601</td> <td> 0.010</td> <td>    0.032</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]</th>                    <td>    0.4814</td> <td>    0.033</td> <td>   14.662</td> <td> 0.000</td> <td>    0.417</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]</th>                    <td>    0.3149</td> <td>    0.051</td> <td>    6.191</td> <td> 0.000</td> <td>    0.214</td> <td>    0.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Demographic]</th>                                          <td>   -0.0123</td> <td>    0.030</td> <td>   -0.406</td> <td> 0.686</td> <td>   -0.072</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Psychometric]</th>                                         <td>    0.1929</td> <td>    0.030</td> <td>    6.407</td> <td> 0.000</td> <td>    0.133</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Round)[T.Mean Originality - Round 5]</th>                         <td>    0.3247</td> <td>    0.023</td> <td>   14.114</td> <td> 0.000</td> <td>    0.279</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Greedy]</th>                                               <td>    0.0579</td> <td>    0.046</td> <td>    1.261</td> <td> 0.209</td> <td>   -0.033</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Random]</th>                                               <td>   -0.2698</td> <td>    0.088</td> <td>   -3.063</td> <td> 0.003</td> <td>   -0.444</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(SSM)[CS]</th>                               <td>    0.1404</td> <td>    0.033</td> <td>    4.276</td> <td> 0.000</td> <td>    0.076</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[CS]</th>                     <td>   -0.0476</td> <td>    0.075</td> <td>   -0.636</td> <td> 0.526</td> <td>   -0.195</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[CS]</th>                      <td>-1.496e-16</td> <td> 1.27e-16</td> <td>   -1.181</td> <td> 0.239</td> <td>   -4e-16</td> <td> 1.01e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[CS]</th>            <td>   -0.1379</td> <td>    0.076</td> <td>   -1.815</td> <td> 0.071</td> <td>   -0.288</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[CS]</th>            <td>    0.2927</td> <td>    0.103</td> <td>    2.845</td> <td> 0.005</td> <td>    0.090</td> <td>    0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[CS]</th>         <td>    0.1003</td> <td>    0.051</td> <td>    1.972</td> <td> 0.050</td> <td>   -0.000</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[CS]</th>     <td>    0.1268</td> <td>    0.051</td> <td>    2.493</td> <td> 0.014</td> <td>    0.026</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(SSM)[Greedy]</th>                           <td>    0.0777</td> <td>    0.055</td> <td>    1.425</td> <td> 0.156</td> <td>   -0.030</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Greedy]</th>                 <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Greedy]</th>                  <td>   -0.0197</td> <td>    0.087</td> <td>   -0.227</td> <td> 0.821</td> <td>   -0.192</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Greedy]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Greedy]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Greedy]</th>     <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Greedy]</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(SSM)[Random]</th>                           <td>    0.3155</td> <td>    0.102</td> <td>    3.101</td> <td> 0.002</td> <td>    0.115</td> <td>    0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Random]</th>                 <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Random]</th>                  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Random]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Random]</th>        <td>    0.5060</td> <td>    0.128</td> <td>    3.951</td> <td> 0.000</td> <td>    0.253</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Random]</th>     <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Random]</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.809</td> <th>  Durbin-Watson:     </th> <td>   1.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.012</td> <th>  Jarque-Bera (JB):  </th> <td>  16.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.152</td> <th>  Prob(JB):          </th> <td>0.000310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.453</td> <th>  Cond. No.          </th> <td>1.44e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.76e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                 &   Originality    & \\textbf{  R-squared:         } &     0.800   \\\\\n",
       "\\textbf{Model:}                                                         &       OLS        & \\textbf{  Adj. R-squared:    } &     0.780   \\\\\n",
       "\\textbf{Method:}                                                        &  Least Squares   & \\textbf{  F-statistic:       } &     39.67   \\\\\n",
       "\\textbf{Date:}                                                          & Wed, 18 Dec 2024 & \\textbf{  Prob (F-statistic):} &  3.67e-47   \\\\\n",
       "\\textbf{Time:}                                                          &     11:55:44     & \\textbf{  Log-Likelihood:    } &    90.089   \\\\\n",
       "\\textbf{No. Observations:}                                              &         176      & \\textbf{  AIC:               } &    -146.2   \\\\\n",
       "\\textbf{Df Residuals:}                                                  &         159      & \\textbf{  BIC:               } &    -92.28   \\\\\n",
       "\\textbf{Df Model:}                                                      &          16      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                               &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                      &       0.7543  &        0.027     &    27.961  &         0.000        &        0.701    &        0.808     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]}                       &       0.1325  &        0.051     &     2.601  &         0.010        &        0.032    &        0.233     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]}                    &       0.4814  &        0.033     &    14.662  &         0.000        &        0.417    &        0.546     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]}                    &       0.3149  &        0.051     &     6.191  &         0.000        &        0.214    &        0.415     \\\\\n",
       "\\textbf{C(RPT)[T.Demographic]}                                          &      -0.0123  &        0.030     &    -0.406  &         0.686        &       -0.072    &        0.048     \\\\\n",
       "\\textbf{C(RPT)[T.Psychometric]}                                         &       0.1929  &        0.030     &     6.407  &         0.000        &        0.133    &        0.252     \\\\\n",
       "\\textbf{C(Round)[T.Mean Originality - Round 5]}                         &       0.3247  &        0.023     &    14.114  &         0.000        &        0.279    &        0.370     \\\\\n",
       "\\textbf{C(SSM)[T.Greedy]}                                               &       0.0579  &        0.046     &     1.261  &         0.209        &       -0.033    &        0.149     \\\\\n",
       "\\textbf{C(SSM)[T.Random]}                                               &      -0.2698  &        0.088     &    -3.063  &         0.003        &       -0.444    &       -0.096     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(SSM)[CS]}                               &       0.1404  &        0.033     &     4.276  &         0.000        &        0.076    &        0.205     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[CS]}                     &      -0.0476  &        0.075     &    -0.636  &         0.526        &       -0.195    &        0.100     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[CS]}                      &   -1.496e-16  &     1.27e-16     &    -1.181  &         0.239        &       -4e-16    &     1.01e-16     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[CS]}            &      -0.1379  &        0.076     &    -1.815  &         0.071        &       -0.288    &        0.012     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[CS]}            &       0.2927  &        0.103     &     2.845  &         0.005        &        0.090    &        0.496     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[CS]}         &       0.1003  &        0.051     &     1.972  &         0.050        &       -0.000    &        0.201     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[CS]}     &       0.1268  &        0.051     &     2.493  &         0.014        &        0.026    &        0.227     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(SSM)[Greedy]}                           &       0.0777  &        0.055     &     1.425  &         0.156        &       -0.030    &        0.185     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Greedy]}                 &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Greedy]}                  &      -0.0197  &        0.087     &    -0.227  &         0.821        &       -0.192    &        0.152     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Greedy]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Greedy]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Greedy]}     &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Greedy]} &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(SSM)[Random]}                           &       0.3155  &        0.102     &     3.101  &         0.002        &        0.115    &        0.516     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Random]}                 &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Random]}                  &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Random]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Random]}        &       0.5060  &        0.128     &     3.951  &         0.000        &        0.253    &        0.759     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Random]}     &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Random]} &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  8.809 & \\textbf{  Durbin-Watson:     } &    1.365  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.012 & \\textbf{  Jarque-Bera (JB):  } &   16.159  \\\\\n",
       "\\textbf{Skew:}          & -0.152 & \\textbf{  Prob(JB):          } & 0.000310  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.453 & \\textbf{  Cond. No.          } & 1.44e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.76e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Originality   R-squared:                       0.800\n",
       "Model:                            OLS   Adj. R-squared:                  0.780\n",
       "Method:                 Least Squares   F-statistic:                     39.67\n",
       "Date:                Wed, 18 Dec 2024   Prob (F-statistic):           3.67e-47\n",
       "Time:                        11:55:44   Log-Likelihood:                 90.089\n",
       "No. Observations:                 176   AIC:                            -146.2\n",
       "Df Residuals:                     159   BIC:                            -92.28\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================================================\n",
       "                                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          0.7543      0.027     27.961      0.000       0.701       0.808\n",
       "C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]                           0.1325      0.051      2.601      0.010       0.032       0.233\n",
       "C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]                        0.4814      0.033     14.662      0.000       0.417       0.546\n",
       "C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]                        0.3149      0.051      6.191      0.000       0.214       0.415\n",
       "C(RPT)[T.Demographic]                                             -0.0123      0.030     -0.406      0.686      -0.072       0.048\n",
       "C(RPT)[T.Psychometric]                                             0.1929      0.030      6.407      0.000       0.133       0.252\n",
       "C(Round)[T.Mean Originality - Round 5]                             0.3247      0.023     14.114      0.000       0.279       0.370\n",
       "C(SSM)[T.Greedy]                                                   0.0579      0.046      1.261      0.209      -0.033       0.149\n",
       "C(SSM)[T.Random]                                                  -0.2698      0.088     -3.063      0.003      -0.444      -0.096\n",
       "C(IGM)[T.gpt-4o-mini]:C(SSM)[CS]                                   0.1404      0.033      4.276      0.000       0.076       0.205\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[CS]                        -0.0476      0.075     -0.636      0.526      -0.195       0.100\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[CS]                      -1.496e-16   1.27e-16     -1.181      0.239      -4e-16    1.01e-16\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[CS]               -0.1379      0.076     -1.815      0.071      -0.288       0.012\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[CS]                0.2927      0.103      2.845      0.005       0.090       0.496\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[CS]             0.1003      0.051      1.972      0.050      -0.000       0.201\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[CS]         0.1268      0.051      2.493      0.014       0.026       0.227\n",
       "C(IGM)[T.gpt-4o-mini]:C(SSM)[Greedy]                               0.0777      0.055      1.425      0.156      -0.030       0.185\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Greedy]                          0          0        nan        nan           0           0\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Greedy]                     -0.0197      0.087     -0.227      0.821      -0.192       0.152\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Greedy]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Greedy]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Greedy]              0          0        nan        nan           0           0\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Greedy]          0          0        nan        nan           0           0\n",
       "C(IGM)[T.gpt-4o-mini]:C(SSM)[Random]                               0.3155      0.102      3.101      0.002       0.115       0.516\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(SSM)[Random]                          0          0        nan        nan           0           0\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(SSM)[Random]                           0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(SSM)[Random]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(SSM)[Random]            0.5060      0.128      3.951      0.000       0.253       0.759\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(SSM)[Random]              0          0        nan        nan           0           0\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(SSM)[Random]          0          0        nan        nan           0           0\n",
       "==============================================================================\n",
       "Omnibus:                        8.809   Durbin-Watson:                   1.365\n",
       "Prob(Omnibus):                  0.012   Jarque-Bera (JB):               16.159\n",
       "Skew:                          -0.152   Prob(JB):                     0.000310\n",
       "Kurtosis:                       4.453   Cond. No.                     1.44e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.76e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction between generator and shot selection method\n",
    "model3 = smf.ols(formula=\"Originality ~ C(IGM) : C(SSM)  + C(IRGM)  + C(RPT) + C(Round)\", data=df)\n",
    "res = model3.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Originality</td>   <th>  R-squared:         </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>6.30e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:26</td>     <th>  Log-Likelihood:    </th> <td>  100.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   176</td>      <th>  AIC:               </th> <td>  -148.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   150</td>      <th>  BIC:               </th> <td>  -65.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    25</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                     <td></td>                                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                              <td>    0.6548</td> <td>    0.106</td> <td>    6.150</td> <td> 0.000</td> <td>    0.444</td> <td>    0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]</th>                                                  <td>    0.2373</td> <td>    0.103</td> <td>    2.305</td> <td> 0.023</td> <td>    0.034</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]</th>                                        <td>    0.0500</td> <td>    0.119</td> <td>    0.421</td> <td> 0.675</td> <td>   -0.185</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]</th>                                         <td>    0.1157</td> <td>    0.077</td> <td>    1.496</td> <td> 0.137</td> <td>   -0.037</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]</th>                               <td>   -0.1122</td> <td>    0.147</td> <td>   -0.765</td> <td> 0.445</td> <td>   -0.402</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]</th>                               <td>    0.2104</td> <td>    0.057</td> <td>    3.692</td> <td> 0.000</td> <td>    0.098</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]</th>                            <td>    0.1087</td> <td>    0.086</td> <td>    1.268</td> <td> 0.207</td> <td>   -0.061</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]</th>                        <td>    0.0475</td> <td>    0.086</td> <td>    0.554</td> <td> 0.580</td> <td>   -0.122</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Demographic]</th>                                                  <td>   -0.0503</td> <td>    0.086</td> <td>   -0.587</td> <td> 0.558</td> <td>   -0.220</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RPT)[T.Psychometric]</th>                                                 <td>    0.2010</td> <td>    0.086</td> <td>    2.345</td> <td> 0.020</td> <td>    0.032</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Round)[T.Mean Originality - Round 5]</th>                                 <td>    0.3247</td> <td>    0.022</td> <td>   14.506</td> <td> 0.000</td> <td>    0.280</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]</th>                               <td>    0.1910</td> <td>    0.139</td> <td>    1.371</td> <td> 0.172</td> <td>   -0.084</td> <td>    0.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]</th>                            <td>    0.5909</td> <td>    0.087</td> <td>    6.806</td> <td> 0.000</td> <td>    0.419</td> <td>    0.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]</th>                            <td>    0.3149</td> <td>    0.049</td> <td>    6.363</td> <td> 0.000</td> <td>    0.217</td> <td>    0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Greedy]</th>                                                       <td>   -0.1142</td> <td>    0.087</td> <td>   -1.316</td> <td> 0.190</td> <td>   -0.286</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(SSM)[T.Random]</th>                                                       <td>   -0.2042</td> <td>    0.071</td> <td>   -2.863</td> <td> 0.005</td> <td>   -0.345</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Demographic]</th>                            <td>    0.0648</td> <td>    0.096</td> <td>    0.676</td> <td> 0.500</td> <td>   -0.125</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Demographic]</th>                  <td>    0.0267</td> <td>    0.129</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.227</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Demographic]</th>                   <td>    0.1157</td> <td>    0.077</td> <td>    1.496</td> <td> 0.137</td> <td>   -0.037</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Demographic]</th>         <td>   -0.0965</td> <td>    0.148</td> <td>   -0.650</td> <td> 0.517</td> <td>   -0.390</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Demographic]</th>         <td>    0.2104</td> <td>    0.057</td> <td>    3.692</td> <td> 0.000</td> <td>    0.098</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Demographic]</th>      <td>    0.0107</td> <td>    0.121</td> <td>    0.088</td> <td> 0.930</td> <td>   -0.229</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Demographic]</th>  <td>    0.1672</td> <td>    0.121</td> <td>    1.379</td> <td> 0.170</td> <td>   -0.072</td> <td>    0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Psychometric]</th>                           <td>   -0.0270</td> <td>    0.096</td> <td>   -0.282</td> <td> 0.778</td> <td>   -0.216</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Psychometric]</th>                 <td>   -0.1515</td> <td>    0.121</td> <td>   -1.250</td> <td> 0.213</td> <td>   -0.391</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Psychometric]</th>                  <td>-4.729e-18</td> <td> 2.01e-18</td> <td>   -2.347</td> <td> 0.020</td> <td>-8.71e-18</td> <td>-7.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Psychometric]</th>        <td>    0.1618</td> <td>    0.148</td> <td>    1.090</td> <td> 0.277</td> <td>   -0.132</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Psychometric]</th>        <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Psychometric]</th>     <td>   -0.0358</td> <td>    0.121</td> <td>   -0.296</td> <td> 0.768</td> <td>   -0.275</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Psychometric]</th> <td>    0.0707</td> <td>    0.121</td> <td>    0.583</td> <td> 0.561</td> <td>   -0.169</td> <td>    0.310</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.001</td> <th>  Durbin-Watson:     </th> <td>   1.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.368</td> <th>  Jarque-Bera (JB):  </th> <td>   1.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.011</td> <th>  Prob(JB):          </th> <td>   0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.494</td> <th>  Cond. No.          </th> <td>1.43e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.92e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                         &   Originality    & \\textbf{  R-squared:         } &     0.821   \\\\\n",
       "\\textbf{Model:}                                                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.791   \\\\\n",
       "\\textbf{Method:}                                                                &  Least Squares   & \\textbf{  F-statistic:       } &     27.54   \\\\\n",
       "\\textbf{Date:}                                                                  & Wed, 18 Dec 2024 & \\textbf{  Prob (F-statistic):} &  6.30e-44   \\\\\n",
       "\\textbf{Time:}                                                                  &     11:57:26     & \\textbf{  Log-Likelihood:    } &    100.04   \\\\\n",
       "\\textbf{No. Observations:}                                                      &         176      & \\textbf{  AIC:               } &    -148.1   \\\\\n",
       "\\textbf{Df Residuals:}                                                          &         150      & \\textbf{  BIC:               } &    -65.64   \\\\\n",
       "\\textbf{Df Model:}                                                              &          25      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                              &       0.6548  &        0.106     &     6.150  &         0.000        &        0.444    &        0.865     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]}                                                  &       0.2373  &        0.103     &     2.305  &         0.023        &        0.034    &        0.441     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]}                                        &       0.0500  &        0.119     &     0.421  &         0.675        &       -0.185    &        0.285     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]}                                         &       0.1157  &        0.077     &     1.496  &         0.137        &       -0.037    &        0.269     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]}                               &      -0.1122  &        0.147     &    -0.765  &         0.445        &       -0.402    &        0.177     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]}                               &       0.2104  &        0.057     &     3.692  &         0.000        &        0.098    &        0.323     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]}                            &       0.1087  &        0.086     &     1.268  &         0.207        &       -0.061    &        0.278     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]}                        &       0.0475  &        0.086     &     0.554  &         0.580        &       -0.122    &        0.217     \\\\\n",
       "\\textbf{C(RPT)[T.Demographic]}                                                  &      -0.0503  &        0.086     &    -0.587  &         0.558        &       -0.220    &        0.119     \\\\\n",
       "\\textbf{C(RPT)[T.Psychometric]}                                                 &       0.2010  &        0.086     &     2.345  &         0.020        &        0.032    &        0.370     \\\\\n",
       "\\textbf{C(Round)[T.Mean Originality - Round 5]}                                 &       0.3247  &        0.022     &    14.506  &         0.000        &        0.280    &        0.369     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]}                               &       0.1910  &        0.139     &     1.371  &         0.172        &       -0.084    &        0.466     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]}                            &       0.5909  &        0.087     &     6.806  &         0.000        &        0.419    &        0.762     \\\\\n",
       "\\textbf{C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]}                            &       0.3149  &        0.049     &     6.363  &         0.000        &        0.217    &        0.413     \\\\\n",
       "\\textbf{C(SSM)[T.Greedy]}                                                       &      -0.1142  &        0.087     &    -1.316  &         0.190        &       -0.286    &        0.057     \\\\\n",
       "\\textbf{C(SSM)[T.Random]}                                                       &      -0.2042  &        0.071     &    -2.863  &         0.005        &       -0.345    &       -0.063     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Demographic]}                            &       0.0648  &        0.096     &     0.676  &         0.500        &       -0.125    &        0.254     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Demographic]}                  &       0.0267  &        0.129     &     0.207  &         0.836        &       -0.227    &        0.281     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Demographic]}                   &       0.1157  &        0.077     &     1.496  &         0.137        &       -0.037    &        0.269     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Demographic]}         &      -0.0965  &        0.148     &    -0.650  &         0.517        &       -0.390    &        0.197     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Demographic]}         &       0.2104  &        0.057     &     3.692  &         0.000        &        0.098    &        0.323     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Demographic]}      &       0.0107  &        0.121     &     0.088  &         0.930        &       -0.229    &        0.250     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Demographic]}  &       0.1672  &        0.121     &     1.379  &         0.170        &       -0.072    &        0.407     \\\\\n",
       "\\textbf{C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Psychometric]}                           &      -0.0270  &        0.096     &    -0.282  &         0.778        &       -0.216    &        0.162     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Psychometric]}                 &      -0.1515  &        0.121     &    -1.250  &         0.213        &       -0.391    &        0.088     \\\\\n",
       "\\textbf{C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Psychometric]}                  &   -4.729e-18  &     2.01e-18     &    -2.347  &         0.020        &    -8.71e-18    &    -7.48e-19     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Psychometric]}        &       0.1618  &        0.148     &     1.090  &         0.277        &       -0.132    &        0.455     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Psychometric]}        &            0  &            0     &       nan  &           nan        &            0    &            0     \\\\\n",
       "\\textbf{C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Psychometric]}     &      -0.0358  &        0.121     &    -0.296  &         0.768        &       -0.275    &        0.204     \\\\\n",
       "\\textbf{C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Psychometric]} &       0.0707  &        0.121     &     0.583  &         0.561        &       -0.169    &        0.310     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.001 & \\textbf{  Durbin-Watson:     } &    1.352  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.368 & \\textbf{  Jarque-Bera (JB):  } &    1.793  \\\\\n",
       "\\textbf{Skew:}          & -0.011 & \\textbf{  Prob(JB):          } &    0.408  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.494 & \\textbf{  Cond. No.          } & 1.43e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.92e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Originality   R-squared:                       0.821\n",
       "Model:                            OLS   Adj. R-squared:                  0.791\n",
       "Method:                 Least Squares   F-statistic:                     27.54\n",
       "Date:                Wed, 18 Dec 2024   Prob (F-statistic):           6.30e-44\n",
       "Time:                        11:57:26   Log-Likelihood:                 100.04\n",
       "No. Observations:                 176   AIC:                            -148.1\n",
       "Df Residuals:                     150   BIC:                            -65.64\n",
       "Df Model:                          25                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================================================\n",
       "                                                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                  0.6548      0.106      6.150      0.000       0.444       0.865\n",
       "C(IGM)[T.gpt-4o-mini]                                                      0.2373      0.103      2.305      0.023       0.034       0.441\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]                                            0.0500      0.119      0.421      0.675      -0.185       0.285\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]                                             0.1157      0.077      1.496      0.137      -0.037       0.269\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]                                  -0.1122      0.147     -0.765      0.445      -0.402       0.177\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]                                   0.2104      0.057      3.692      0.000       0.098       0.323\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]                                0.1087      0.086      1.268      0.207      -0.061       0.278\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]                            0.0475      0.086      0.554      0.580      -0.122       0.217\n",
       "C(RPT)[T.Demographic]                                                     -0.0503      0.086     -0.587      0.558      -0.220       0.119\n",
       "C(RPT)[T.Psychometric]                                                     0.2010      0.086      2.345      0.020       0.032       0.370\n",
       "C(Round)[T.Mean Originality - Round 5]                                     0.3247      0.022     14.506      0.000       0.280       0.369\n",
       "C(IRGM)[T.meta-llama/Llama-2-7b-chat-hf]                                   0.1910      0.139      1.371      0.172      -0.084       0.466\n",
       "C(IRGM)[T.meta-llama/Llama-3.1-8B-Instruct]                                0.5909      0.087      6.806      0.000       0.419       0.762\n",
       "C(IRGM)[T.meta-llama/Llama-3.2-3B-Instruct]                                0.3149      0.049      6.363      0.000       0.217       0.413\n",
       "C(SSM)[T.Greedy]                                                          -0.1142      0.087     -1.316      0.190      -0.286       0.057\n",
       "C(SSM)[T.Random]                                                          -0.2042      0.071     -2.863      0.005      -0.345      -0.063\n",
       "C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Demographic]                                0.0648      0.096      0.676      0.500      -0.125       0.254\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Demographic]                      0.0267      0.129      0.207      0.836      -0.227       0.281\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Demographic]                       0.1157      0.077      1.496      0.137      -0.037       0.269\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Demographic]            -0.0965      0.148     -0.650      0.517      -0.390       0.197\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Demographic]             0.2104      0.057      3.692      0.000       0.098       0.323\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Demographic]          0.0107      0.121      0.088      0.930      -0.229       0.250\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Demographic]      0.1672      0.121      1.379      0.170      -0.072       0.407\n",
       "C(IGM)[T.gpt-4o-mini]:C(RPT)[T.Psychometric]                              -0.0270      0.096     -0.282      0.778      -0.216       0.162\n",
       "C(IGM)[T.lmsys/vicuna-13b-v1.5]:C(RPT)[T.Psychometric]                    -0.1515      0.121     -1.250      0.213      -0.391       0.088\n",
       "C(IGM)[T.lmsys/vicuna-7b-v1.5]:C(RPT)[T.Psychometric]                  -4.729e-18   2.01e-18     -2.347      0.020   -8.71e-18   -7.48e-19\n",
       "C(IGM)[T.meta-llama/Llama-2-13b-chat-hf]:C(RPT)[T.Psychometric]            0.1618      0.148      1.090      0.277      -0.132       0.455\n",
       "C(IGM)[T.meta-llama/Llama-2-70b-chat-hf]:C(RPT)[T.Psychometric]                 0          0        nan        nan           0           0\n",
       "C(IGM)[T.meta-llama/Llama-3.1-70B-Instruct]:C(RPT)[T.Psychometric]        -0.0358      0.121     -0.296      0.768      -0.275       0.204\n",
       "C(IGM)[T.mistralai/Mistral-Large-Instruct-2407]:C(RPT)[T.Psychometric]     0.0707      0.121      0.583      0.561      -0.169       0.310\n",
       "==============================================================================\n",
       "Omnibus:                        2.001   Durbin-Watson:                   1.352\n",
       "Prob(Omnibus):                  0.368   Jarque-Bera (JB):                1.793\n",
       "Skew:                          -0.011   Prob(JB):                        0.408\n",
       "Kurtosis:                       3.494   Cond. No.                     1.43e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.92e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction between prompt type and round\n",
    "model4 = smf.ols(formula=\"Originality ~ C(IGM) : C(RPT) + C(IGM) + C(RPT) + C(Round) + C(IRGM) + C(SSM)\", data=df)\n",
    "res = model4.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Ratio: 21.888000000000005\n",
      "P-value: 0.984314552076855\n"
     ]
    }
   ],
   "source": [
    "# likelihood ratio test TODO: confirm this is accurate and the test is appropriate (assumes models are nested I belive)\n",
    "from scipy.stats import chi2\n",
    "np.random.seed(0)\n",
    "\n",
    "full_ll = 100.04 # model4\n",
    "reduced_ll = 89.096 # model1\n",
    "full_params = model4.df_resid\n",
    "reduced_params = model1.df_resid\n",
    "\n",
    "# Calculate the likelihood ratio\n",
    "lr = -2 * (reduced_ll - full_ll)\n",
    "lrdf = (reduced_params - full_params)\n",
    "p_value = 1 - chi2.sf(lr, df=lrdf)\n",
    "\n",
    "print(\"Likelihood Ratio:\", lr)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIG-CUDA-12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
