{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aml7990/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Using an industry model, check for hallucinations between generated items and item responses.\n",
    "    Basically, we need a measure of faithfullness that the responder agent actually answered the generator agent\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from os.path import join\n",
    "item_gen_path = \"/home/aml7990/Code/creativity-item-generation/outputs/CPS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from the analyze outputs script\n",
    "# TODO: probably helpful enough to make a function as a top level util.py\n",
    "use_rescored = False\n",
    "dirs = [\n",
    "    d\n",
    "    for d in os.listdir(item_gen_path)\n",
    "    if os.path.isdir(os.path.join(item_gen_path, d))\n",
    "]\n",
    "all_items_round_0 = []\n",
    "all_item_responses_round_0 = []\n",
    "all_item_responses_round_4 = []\n",
    "all_items_round_4 = []\n",
    "for d in dirs:\n",
    "    # skip over runs that are still processing:\n",
    "    print(d)\n",
    "    files = os.listdir(join(item_gen_path, d))\n",
    "    if use_rescored:\n",
    "        if \"config.json\" not in files or \"items.json\" not in files or \"item_responses_round_0_rescored.json\" not in files or \"item_responses_round_4_rescored.json\" not in files:\n",
    "            continue\n",
    "    else:\n",
    "        if \"config.json\" not in files or \"items.json\" not in files or \"item_responses_round_0.json\" not in files or \"item_responses_round_4.json\" not in files:\n",
    "            continue\n",
    "    items = pd.read_json(join(item_gen_path, d, \"items.json\"))\n",
    "    config = pd.read_json(join(item_gen_path, d, \"config.json\"), typ='series')\n",
    "    if use_rescored:\n",
    "        item_responses_round_0 = pd.read_json(join(item_gen_path, d, \"item_responses_round_0_rescored.json\"))\n",
    "        item_responses_round_4 = pd.read_json(join(item_gen_path, d, \"item_responses_round_4_rescored.json\"))\n",
    "    else:\n",
    "        item_responses_round_0 = pd.read_json(join(item_gen_path, d, \"item_responses_round_0.json\"))\n",
    "        item_responses_round_4 = pd.read_json(join(item_gen_path, d, \"item_responses_round_4.json\"))\n",
    "    if len(items) == 0:\n",
    "        continue\n",
    "\n",
    "    items_round_0 = items[\n",
    "        [\"creative_scenario_round_0\", \"word_list\", \"item_gen_model_name\"]\n",
    "    ]\n",
    "    items_round_4 = items[\n",
    "        [\"creative_scenario_round_4\", \"word_list\", \"item_gen_model_name\"]\n",
    "    ]\n",
    "    items_round_0[\"originality_mean\"] = item_responses_round_0[\"originality_round_0\"].mean()\n",
    "    items_round_4[\"originality_mean\"] = item_responses_round_4[\"originality_round_4\"].mean()\n",
    "    items_round_0[\"itemResponsePrompt\"] = config[\"itemResponseGenPromptIdx\"]\n",
    "    items_round_4[\"itemResponsePrompt\"] = config[\"itemResponseGenPromptIdx\"]\n",
    "    config = pd.read_json(join(item_gen_path, d, \"config.json\"), orient=\"index\").T\n",
    "    combined_round_0 = items_round_0.merge(\n",
    "        config, how=\"outer\", left_on=\"item_gen_model_name\", right_on=\"itemGenModelName\"\n",
    "    )\n",
    "    combined_round_4 = items_round_4.merge(\n",
    "        config, how=\"outer\", left_on=\"item_gen_model_name\", right_on=\"itemGenModelName\"\n",
    "    )\n",
    "    if \"/\" in combined_round_0[\"itemGenModelName\"].iloc[0]:\n",
    "        combined_round_0[\"itemGenModelName\"] = combined_round_0[\"itemGenModelName\"].iloc[0].split(\"/\")[1]\n",
    "    if \"/\" in combined_round_4[\"itemGenModelName\"].iloc[0]:\n",
    "        combined_round_4[\"itemGenModelName\"] = combined_round_4[\"itemGenModelName\"].iloc[0].split(\"/\")[1]\n",
    "    all_items_round_0.append(combined_round_0)\n",
    "    all_items_round_4.append(combined_round_4)\n",
    "    all_item_responses_round_0.append(item_responses_round_0)\n",
    "    all_item_responses_round_4.append(item_responses_round_4)\n",
    "\n",
    "all_items_round_0 = pd.concat(all_items_round_0).reset_index(drop=True)\n",
    "all_items_round_4 = pd.concat(all_items_round_4).reset_index(drop=True)\n",
    "all_item_responses_round_0 = pd.concat(all_item_responses_round_0).reset_index(drop=True)\n",
    "all_item_responses_round_4 = pd.concat(all_item_responses_round_4).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection using an off the shelf hallucination model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_responses_round_0 = all_item_responses_round_0[[\"creative_scenario_round_0\",\"creative_response_round_0\"]].to_records(index=False).tolist()\n",
    "all_item_responses_round_4 = all_item_responses_round_4[[\"creative_scenario_round_4\",\"creative_response_round_4\"]].to_records(index=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('vectara/hallucination_evaluation_model', trust_remote_code=True).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 135/500 [00:04<00:13, 27.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m round_0_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m tqdm(all_item_responses_round_0[:\u001b[38;5;241m500\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     round_0_preds\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()))\n",
      "File \u001b[0;32m~/hf-models/modules/transformers_modules/vectara/hallucination_evaluation_model/b3973afb9f9595a40bb8403b46c6dac9c26d16d5/modeling_hhem_v2.py:65\u001b[0m, in \u001b[0;36mHHEMv2ForSequenceClassification.predict\u001b[0;34m(self, text_pairs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt5\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 65\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits    \n\u001b[1;32m     67\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m0\u001b[39m, :] \u001b[38;5;66;03m# tok_cls\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:2158\u001b[0m, in \u001b[0;36mT5ForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2156\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 2158\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2162\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2163\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2168\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2169\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1971\u001b[0m, in \u001b[0;36mT5EncoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m   1955\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[38;5;124;03m>>> last_hidden_states = outputs.last_hidden_state\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1971\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1979\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:746\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    743\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:335\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    334\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 335\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:318\u001b[0m, in \u001b[0;36mT5DenseGatedActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m    315\u001b[0m ):\n\u001b[1;32m    316\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 318\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/AIG-CUDA-12.0/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "round_0_preds = []\n",
    "for response in tqdm(all_item_responses_round_0[:500]):\n",
    "    round_0_preds.append(float(model.predict([response]).detach().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:16<00:00, 31.21it/s]\n"
     ]
    }
   ],
   "source": [
    "round_4_preds = []\n",
    "for response in tqdm(all_item_responses_round_4[:500]):\n",
    "    round_4_preds.append(float(model.predict([response]).detach().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(round_0_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(round_4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.181017205119133,\n",
       " 0.09872841089963913,\n",
       " 0.04060767590999603,\n",
       " 0.5762943625450134,\n",
       " 0.11129254847764969,\n",
       " 0.041440874338150024,\n",
       " 0.10570655018091202,\n",
       " 0.21028733253479004,\n",
       " 0.7318072319030762,\n",
       " 0.3370550870895386]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_0_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Sarah is a young professional living in a bustling city. She loves to go for runs in the local park to clear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her mind and stay active. One day while on her usual run, she sees her coworker Michael and her friend Emma engaged</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in a heated conversation in the middle of the park. Sarah tries to avoid them, not wanting to get caught up in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">their dispute, but she can't help but overhear their argument. \\n\\nIt becomes clear that Michael and Emma have been</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dating in secret, but Michael has just revealed to Emma that he is actually engaged to another woman named Sarah - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a different Sarah, not the Sarah who is watching the scene unfold. Emma is understandably upset and confronts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Michael about his deception. Michael tries to explain and plead with Emma, but Emma is furious and threatens to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expose their affair to the other Sarah.\\n\\nSarah, the observer, is now in a difficult position. She has </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inadvertently become privy to sensitive information that could impact multiple people's lives. She knows the right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thing to do would be to distance herself and let Michael and Emma resolve their own issues. However, she also feels</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">compelled to protect her namesake, the other Sarah who is engaged to Michael. Sarah doesn't know if she should </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intervene in the argument, contact the other Sarah, or simply walk away and pretend she saw nothing.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Sarah should quietly slip away from the scene, not wanting to get involved in the argument or potentially </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">escalate the situation. She should then discreetly contact the other Sarah, informing her about the situation and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">advising her to be prepared for a potentially difficult conversation with Michael. Sarah should then keep a low </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">profile, avoiding any further interactions with Michael and Emma, and let them work out their issues on their own. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This way, Sarah can maintain her distance while still being a good friend and ally to the other Sarah'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[32m\"Sarah is a young professional living in a bustling city. She loves to go for runs in the local park to clear \u001b[0m\n",
       "\u001b[32mher mind and stay active. One day while on her usual run, she sees her coworker Michael and her friend Emma engaged\u001b[0m\n",
       "\u001b[32min a heated conversation in the middle of the park. Sarah tries to avoid them, not wanting to get caught up in \u001b[0m\n",
       "\u001b[32mtheir dispute, but she can't help but overhear their argument. \\n\\nIt becomes clear that Michael and Emma have been\u001b[0m\n",
       "\u001b[32mdating in secret, but Michael has just revealed to Emma that he is actually engaged to another woman named Sarah - \u001b[0m\n",
       "\u001b[32ma different Sarah, not the Sarah who is watching the scene unfold. Emma is understandably upset and confronts \u001b[0m\n",
       "\u001b[32mMichael about his deception. Michael tries to explain and plead with Emma, but Emma is furious and threatens to \u001b[0m\n",
       "\u001b[32mexpose their affair to the other Sarah.\\n\\nSarah, the observer, is now in a difficult position. She has \u001b[0m\n",
       "\u001b[32minadvertently become privy to sensitive information that could impact multiple people's lives. She knows the right \u001b[0m\n",
       "\u001b[32mthing to do would be to distance herself and let Michael and Emma resolve their own issues. However, she also feels\u001b[0m\n",
       "\u001b[32mcompelled to protect her namesake, the other Sarah who is engaged to Michael. Sarah doesn't know if she should \u001b[0m\n",
       "\u001b[32mintervene in the argument, contact the other Sarah, or simply walk away and pretend she saw nothing.\"\u001b[0m,\n",
       "    \u001b[32m'Sarah should quietly slip away from the scene, not wanting to get involved in the argument or potentially \u001b[0m\n",
       "\u001b[32mescalate the situation. She should then discreetly contact the other Sarah, informing her about the situation and \u001b[0m\n",
       "\u001b[32madvising her to be prepared for a potentially difficult conversation with Michael. Sarah should then keep a low \u001b[0m\n",
       "\u001b[32mprofile, avoiding any further interactions with Michael and Emma, and let them work out their issues on their own. \u001b[0m\n",
       "\u001b[32mThis way, Sarah can maintain her distance while still being a good friend and ally to the other Sarah'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print as rprint\n",
    "rprint(all_item_responses_round_0[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection using set difference of NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_responses_round_0 = all_item_responses_round_0[[\"creative_scenario_round_0\",\"creative_response_round_0\"]]\n",
    "all_item_responses_round_4 = all_item_responses_round_4[[\"creative_scenario_round_4\",\"creative_response_round_4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_responses_round_0[\"scenario_set\"] = None\n",
    "all_item_responses_round_0[\"response_set\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_func(row):\n",
    "#     doc1 = nlp(row[\"creative_scenario_round_0\"])\n",
    "#     doc2 = nlp(row[\"creative_response_round_0\"])\n",
    "#     doc1_ents = set()\n",
    "#     doc2_ents = set()\n",
    "#     for ent in doc1.ents:\n",
    "#         doc1_ents.add(ent.text)\n",
    "#     for ent in doc2.ents:\n",
    "#         doc2_ents.add(ent.text)\n",
    "    \n",
    "#     row[\"scenario_set\"] = doc1_ents\n",
    "#     row[\"response_set\"] = doc2_ents\n",
    "# all_item_responses_round_0.parallel_apply(lambda x: apply_func(x), axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 500/68130 [00:14<31:42, 35.55it/s] \n"
     ]
    }
   ],
   "source": [
    "from rich import print as rprint\n",
    "from tqdm import tqdm\n",
    "for index, row in tqdm(all_item_responses_round_0[:500].iterrows(), total=len(all_item_responses_round_0)):\n",
    "    doc1 = nlp(row[\"creative_scenario_round_0\"])\n",
    "    doc2 = nlp(row[\"creative_response_round_0\"])\n",
    "    doc1_ents = set()\n",
    "    doc2_ents = set()\n",
    "    for ent in doc1.ents:\n",
    "        doc1_ents.add(ent.text)\n",
    "    for ent in doc2.ents:\n",
    "        doc2_ents.add(ent.text)\n",
    "    \n",
    "    all_item_responses_round_0.at[index, \"scenario_set\"] = doc1_ents\n",
    "    all_item_responses_round_0.at[index, \"response_set\"] = doc2_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_responses_round_0[\"edit distance\"] = all_item_responses_round_0[\"response_set\"] - all_item_responses_round_0[\"scenario_set\"]\n",
    "\n",
    "all_item_responses_round_0[\"edit distance\"] = all_item_responses_round_0[\"edit distance\"].apply(lambda x: len(x) if type(x) == set else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edit distance\n",
       "0.0    386\n",
       "1.0     95\n",
       "2.0     16\n",
       "3.0      2\n",
       "4.0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_item_responses_round_0[\"edit distance\"].dropna().value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIG-CUDA-12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
