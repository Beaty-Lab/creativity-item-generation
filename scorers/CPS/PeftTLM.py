"""
    Parameter-efficient finetuning of scorers. Including LoRA, QLoRA, AdaLoRA orthogonal finetuning, and prefix-tuning and p-tuning
    Use LLama-3, Gemma, and Flan-T5.
    Add OFT/BOFT if time permitting and performance justifies it
"""
# TODO: finish, separateme methods for tuning and inference using sklearn-like API